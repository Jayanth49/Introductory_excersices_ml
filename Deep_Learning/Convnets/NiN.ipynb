{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from res.plot_lib import plot_data, plot_model, set_default\n",
    "set_default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize=100\n",
    "transform = transforms.Compose([transforms.Resize(224),transforms.ToTensor()])\n",
    " \n",
    "train_set = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batchSize, shuffle=True, num_workers=0)\n",
    " \n",
    "test_set = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batchSize, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nin_block(in_channels, out_channels, kernel_size, strides, padding):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size, strides, padding),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(out_channels, out_channels, kernel_size=1), nn.ReLU(),\n",
    "        nn.Conv2d(out_channels, out_channels, kernel_size=1), nn.ReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionCNN_NiN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FashionCNN_NiN, self).__init__()\n",
    "            \n",
    "        self.net = nn.Sequential(\n",
    "            nin_block(1, 96, kernel_size=11, strides=4, padding=0),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "            nin_block(96, 256, kernel_size=5, strides=1, padding=2),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "            nin_block(256, 384, kernel_size=3, strides=1, padding=1),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "            nn.Dropout(0.5),\n",
    "            # There are 10 label classes\n",
    "            nin_block(384, 10, kernel_size=3, strides=1, padding=1),\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            # Transform the four-dimensional output into two-dimensional output with a\n",
    "            # shape of (batch size, 10)\n",
    "            nn.Flatten())\n",
    "        \n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FashionCNN_NiN(\n",
      "  (net): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(1, 96, kernel_size=(11, 11), stride=(4, 4))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): Sequential(\n",
      "      (0): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Sequential(\n",
      "      (0): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Dropout(p=0.5, inplace=False)\n",
      "    (7): Sequential(\n",
      "      (0): Conv2d(384, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(10, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(10, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (9): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = FashionCNN_NiN()\n",
    "model.to(device)\n",
    "\n",
    "error = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "count = 0\n",
    "# Lists for visualization of loss and accuracy \n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "# Lists for knowing classwise accuracy\n",
    "predictions_list = []\n",
    "labels_list = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in train_loader:\n",
    "        # Transfering images and labels to GPU if available\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "        train = Variable(images.view(100, 1, 224, 224))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Forward pass \n",
    "        outputs = model(train)\n",
    "        loss = error(outputs, labels)\n",
    "        \n",
    "        # Initializing a gradient as 0 so there is no mixing of gradient among the batches\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #Propagating the error backward\n",
    "        loss.backward()\n",
    "        \n",
    "        # Optimizing the parameters\n",
    "        optimizer.step()\n",
    "    \n",
    "        count += 1\n",
    "    \n",
    "    # Testing the model\n",
    "    \n",
    "        if not (count % 50):    # It's same as \"if count % 50 == 0\"\n",
    "            total = 0\n",
    "            correct = 0\n",
    "        \n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                labels_list.append(labels)\n",
    "            \n",
    "                test = Variable(images.view(100, 1, 224, 224))\n",
    "            \n",
    "                outputs = model(test)\n",
    "            \n",
    "                predictions = torch.max(outputs, 1)[1].to(device)\n",
    "                predictions_list.append(predictions)\n",
    "                correct += (predictions == labels).sum()\n",
    "            \n",
    "                total += len(labels)\n",
    "            \n",
    "            accuracy = correct * 100 / total\n",
    "            loss_list.append(loss.data)\n",
    "            iteration_list.append(count)\n",
    "            accuracy_list.append(accuracy)\n",
    "        \n",
    "        if not (count % 500):\n",
    "            print(\"Iteration: {}, Loss: {}, Accuracy: {}%\".format(count, loss.data, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
